{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------\n",
    "#sequence-to-sequence word-level chatbot (teacher forcing style).\n",
    "#----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46b0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163aa89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'what is your name', 'what is your hobby', 'which is your favourite colour', 'your favourite food', 'your education', 'you know tamil', 'hi', 'what is your name', 'what is your hobby', 'which is your favourite colour', 'your favourite food', 'your education', 'you know tamil', 'your name', 'do you know tamil', 'my name is nirmal', 'my name is kumar', 'my name is star', 'my name is moon', 'my name is jhon what is your name']\n",
      "['hello', 'chatbot', 'chating', 'blue', 'sweets', 'engineer', 'yes', 'hello', 'chatbot', 'chating', 'blue', 'sweets', 'engineer', 'yes', 'chatbot', 'yes i known tamil', 'Hi nirmal', 'Hi kumar', 'Hi star', 'Hi moonsun', 'chatbot']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"nrmal.csv\")\n",
    "questions = df[\"question\"].astype(str).tolist()\n",
    "answers = df[\"answer\"].astype(str).tolist()\n",
    "\n",
    "print(questions)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "752ec250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 32\n",
      "{'hi': 1, 'what': 2, 'is': 3, 'your': 4, 'name': 5, 'hobby': 6, 'which': 7, 'favourite': 8, 'colour': 9, 'food': 10, 'education': 11, 'you': 12, 'know': 13, 'tamil': 14, 'do': 15, 'my': 16, 'nirmal': 17, 'kumar': 18, 'star': 19, 'moon': 20, 'jhon': 21, 'hello': 22, 'chatbot': 23, 'chating': 24, 'blue': 25, 'sweets': 26, 'engineer': 27, 'yes': 28, 'i': 29, 'known': 30, 'moonsun': 31}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tokenize(sentences):\n",
    "    words = []\n",
    "    for s in sentences:\n",
    "        words.extend(s.lower().split())\n",
    "    return words\n",
    "\n",
    "all_words = tokenize(questions + answers)\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "word2idx = {word: i+1 for i, (word, _) in enumerate(word_counts.items())}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "vocab_size = len(word2idx) + 1  # padding = 0\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85b7af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 8\n",
      "[[1], [2, 3, 4, 5], [2, 3, 4, 6], [7, 3, 4, 8, 9], [4, 8, 10], [4, 11], [12, 13, 14], [1], [2, 3, 4, 5], [2, 3, 4, 6], [7, 3, 4, 8, 9], [4, 8, 10], [4, 11], [12, 13, 14], [4, 5], [15, 12, 13, 14], [16, 5, 3, 17], [16, 5, 3, 18], [16, 5, 3, 19], [16, 5, 3, 20], [16, 5, 3, 21, 2, 3, 4, 5]]\n",
      "[[22], [23], [24], [25], [26], [27], [28], [22], [23], [24], [25], [26], [27], [28], [23], [28, 29, 30, 14], [1, 17], [1, 18], [1, 19], [1, 31], [23]]\n"
     ]
    }
   ],
   "source": [
    "def text_to_sequence(texts):\n",
    "    return [[word2idx[w] for w in t.lower().split() if w in word2idx] for t in texts]\n",
    "\n",
    "X_seq = text_to_sequence(questions)\n",
    "y_seq = text_to_sequence(answers)\n",
    "\n",
    "max_len = max(max(len(s) for s in X_seq), max(len(s) for s in y_seq))\n",
    "print(\"Max length:\", max_len)\n",
    "print(X_seq)\n",
    "print(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24f4dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  3,  4,  5,  0,  0,  0,  0],\n",
      "        [ 2,  3,  4,  6,  0,  0,  0,  0],\n",
      "        [ 7,  3,  4,  8,  9,  0,  0,  0],\n",
      "        [ 4,  8, 10,  0,  0,  0,  0,  0],\n",
      "        [ 4, 11,  0,  0,  0,  0,  0,  0],\n",
      "        [12, 13, 14,  0,  0,  0,  0,  0],\n",
      "        [ 1,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  3,  4,  5,  0,  0,  0,  0],\n",
      "        [ 2,  3,  4,  6,  0,  0,  0,  0],\n",
      "        [ 7,  3,  4,  8,  9,  0,  0,  0],\n",
      "        [ 4,  8, 10,  0,  0,  0,  0,  0],\n",
      "        [ 4, 11,  0,  0,  0,  0,  0,  0],\n",
      "        [12, 13, 14,  0,  0,  0,  0,  0],\n",
      "        [ 4,  5,  0,  0,  0,  0,  0,  0],\n",
      "        [15, 12, 13, 14,  0,  0,  0,  0],\n",
      "        [16,  5,  3, 17,  0,  0,  0,  0],\n",
      "        [16,  5,  3, 18,  0,  0,  0,  0],\n",
      "        [16,  5,  3, 19,  0,  0,  0,  0],\n",
      "        [16,  5,  3, 20,  0,  0,  0,  0],\n",
      "        [16,  5,  3, 21,  2,  3,  4,  5]])\n",
      "tensor([[22,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [23,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [24,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [25,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [26,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [27,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [28,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [22,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [23,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [24,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [25,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [26,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [27,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [28,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [23,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [28, 29, 30, 14,  0,  0,  0,  0],\n",
      "        [ 1, 17,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 18,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 19,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 31,  0,  0,  0,  0,  0,  0],\n",
      "        [23,  0,  0,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "def pad_sequences(sequences, max_len):\n",
    "    padded = np.zeros((len(sequences), max_len), dtype=np.int64)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        padded[i, :len(seq)] = seq\n",
    "    return padded\n",
    "\n",
    "X = pad_sequences(X_seq, max_len)\n",
    "y = pad_sequences(y_seq, max_len)\n",
    "\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b258d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, embed_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3245bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "model = ChatbotLSTM(vocab_size, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebaaef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5822\n",
      "Epoch 20, Loss: 0.5766\n",
      "Epoch 40, Loss: 0.5757\n",
      "Epoch 60, Loss: 0.5753\n",
      "Epoch 80, Loss: 0.5752\n",
      "Epoch 100, Loss: 0.5751\n",
      "Epoch 120, Loss: 0.5750\n",
      "Epoch 140, Loss: 0.5750\n",
      "Epoch 160, Loss: 0.5750\n",
      "Epoch 180, Loss: 0.5749\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs.view(-1, vocab_size), y.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d9dd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"word2idx\": word2idx,\n",
    "    \"idx2word\": idx2word,\n",
    "    \"max_len\": max_len\n",
    "}, \"models/lstm_chatbot.pth\")\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e18ec098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(question):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        seq = [word2idx.get(w, 0) for w in question.lower().split()]\n",
    "        seq = seq[:max_len]\n",
    "        padded = torch.zeros(1, max_len, dtype=torch.long)\n",
    "        padded[0, :len(seq)] = torch.tensor(seq)\n",
    "\n",
    "        output = model(padded)\n",
    "        pred_ids = torch.argmax(output, dim=-1)[0]\n",
    "\n",
    "        words = [idx2word[i.item()] for i in pred_ids if i.item() > 0]\n",
    "        return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "235e4201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: chating chatbot chatbot kumar yes yes yes i\n"
     ]
    }
   ],
   "source": [
    "test_question = \"what is your name\"\n",
    "response = predict_answer(test_question)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e03064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'exit' to quit.\n",
      "Chatbot: chating chatbot chatbot kumar yes yes yes i\n",
      "Chatbot: yes i known tamil tamil tamil tamil i\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is ready! Type 'exit' to quit.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    response = predict_answer(user_input)\n",
    "    print(\"Chatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a55ca510",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"models/lstm_chatbot.pth\", map_location=\"cpu\")\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "word2idx = checkpoint[\"word2idx\"]\n",
    "idx2word = checkpoint[\"idx2word\"]\n",
    "max_len = checkpoint[\"max_len\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "313b28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"models/lstm_chatbot.pth\"\n",
    "os.makedirs(os.path.dirname(path), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ddda4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5259057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, embed_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22ce61a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "path = \"models/lstm_chatbot.pth\"\n",
    "\n",
    "checkpoint = torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "word2idx = checkpoint[\"word2idx\"]\n",
    "idx2word = checkpoint[\"idx2word\"]\n",
    "max_len = checkpoint[\"max_len\"]\n",
    "\n",
    "vocab_size = len(word2idx) + 1\n",
    "embedding_dim = 128   # MUST match training\n",
    "\n",
    "model = ChatbotLSTM(vocab_size, embedding_dim)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "291a04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(question):\n",
    "    with torch.no_grad():\n",
    "        tokens = question.lower().split()\n",
    "        seq = [word2idx.get(w, 0) for w in tokens]\n",
    "\n",
    "        seq = seq[:max_len]\n",
    "\n",
    "        padded = torch.zeros(1, max_len, dtype=torch.long)\n",
    "        padded[0, :len(seq)] = torch.tensor(seq)\n",
    "\n",
    "        output = model(padded)\n",
    "\n",
    "        pred_ids = torch.argmax(output, dim=-1)[0]\n",
    "\n",
    "        words = [idx2word[i.item()] for i in pred_ids if i.item() > 0]\n",
    "        return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235ff17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chating chatbot chatbot kumar yes yes yes i\n",
      "yes i yes i known tamil tamil tamil\n"
     ]
    }
   ],
   "source": [
    "print(predict_answer(\"what is your name\"))\n",
    "print(predict_answer(\"how are you\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0815de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'exit' to quit.\n",
      "Chatbot: yes known tamil tamil tamil i i known\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is ready! Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    response = predict_answer(user_input)\n",
    "    print(\"Chatbot:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
