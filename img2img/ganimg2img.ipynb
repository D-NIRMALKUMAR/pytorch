{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b4b4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aaf725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 200\n",
    "LAMBDA_L1 = 100\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c3cfdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.real_dir = os.path.join(root, \"real\")\n",
    "        self.comic_dir = os.path.join(root, \"comic\")\n",
    "        self.images = os.listdir(self.real_dir)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.images[idx]\n",
    "        real = Image.open(os.path.join(self.real_dir, name)).convert(\"RGB\")\n",
    "        comic = Image.open(os.path.join(self.comic_dir, name)).convert(\"RGB\")\n",
    "\n",
    "        return self.transform(real), self.transform(comic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d131e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        def down(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 4, 2, 1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        def up(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_c, out_c, 4, 2, 1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.d1 = down(3, 64)\n",
    "        self.d2 = down(64, 128)\n",
    "        self.d3 = down(128, 256)\n",
    "        self.d4 = down(256, 512)\n",
    "\n",
    "        self.u1 = up(512, 256)\n",
    "        self.u2 = up(512, 128)\n",
    "        self.u3 = up(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.d1(x)\n",
    "        d2 = self.d2(d1)\n",
    "        d3 = self.d3(d2)\n",
    "        d4 = self.d4(d3)\n",
    "\n",
    "        u1 = self.u1(d4)\n",
    "        u2 = self.u2(torch.cat([u1, d3], 1))\n",
    "        u3 = self.u3(torch.cat([u2, d2], 1))\n",
    "\n",
    "        return self.final(torch.cat([u3, d1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cba3c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 1, 4, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.model(torch.cat([x, y], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c5dbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | D: 0.6675 | G: 39.2742\n",
      "Epoch 1 | D: 0.6253 | G: 37.8299\n",
      "Epoch 2 | D: 0.6088 | G: 30.1862\n",
      "Epoch 3 | D: 0.5976 | G: 25.2234\n",
      "Epoch 4 | D: 0.6354 | G: 19.6381\n",
      "Epoch 5 | D: 0.6090 | G: 16.9838\n",
      "Epoch 6 | D: 0.6063 | G: 15.8521\n",
      "Epoch 7 | D: 0.5731 | G: 15.4483\n",
      "Epoch 8 | D: 0.5565 | G: 14.3382\n",
      "Epoch 9 | D: 0.5042 | G: 12.5873\n",
      "Epoch 10 | D: 0.4874 | G: 14.2626\n",
      "Epoch 11 | D: 0.4376 | G: 13.2247\n",
      "Epoch 12 | D: 0.5476 | G: 12.8965\n",
      "Epoch 13 | D: 0.4647 | G: 12.6731\n",
      "Epoch 14 | D: 0.4236 | G: 13.3178\n",
      "Epoch 15 | D: 0.3965 | G: 12.3911\n",
      "Epoch 16 | D: 0.3614 | G: 11.6619\n",
      "Epoch 17 | D: 0.3814 | G: 11.5810\n",
      "Epoch 18 | D: 0.4841 | G: 12.2905\n",
      "Epoch 19 | D: 0.4464 | G: 12.0989\n",
      "Epoch 20 | D: 0.3683 | G: 11.1056\n",
      "Epoch 21 | D: 0.3593 | G: 10.6318\n",
      "Epoch 22 | D: 0.4167 | G: 11.5636\n",
      "Epoch 23 | D: 0.4351 | G: 10.1235\n",
      "Epoch 24 | D: 0.5154 | G: 10.5241\n",
      "Epoch 25 | D: 0.4060 | G: 10.2519\n",
      "Epoch 26 | D: 0.3110 | G: 11.2847\n",
      "Epoch 27 | D: 0.3072 | G: 9.7368\n",
      "Epoch 28 | D: 0.2730 | G: 9.9237\n",
      "Epoch 29 | D: 0.2588 | G: 10.2447\n",
      "Epoch 30 | D: 0.3472 | G: 9.7571\n",
      "Epoch 31 | D: 0.2893 | G: 10.7163\n",
      "Epoch 32 | D: 0.2508 | G: 10.5354\n",
      "Epoch 33 | D: 0.2350 | G: 10.2631\n",
      "Epoch 34 | D: 0.2255 | G: 9.7031\n",
      "Epoch 35 | D: 0.3090 | G: 9.4052\n",
      "Epoch 36 | D: 0.3292 | G: 10.3575\n",
      "Epoch 37 | D: 0.2734 | G: 9.6339\n",
      "Epoch 38 | D: 0.2735 | G: 10.5472\n",
      "Epoch 39 | D: 0.3039 | G: 9.5838\n",
      "Epoch 40 | D: 0.3284 | G: 9.1712\n",
      "Epoch 41 | D: 0.2817 | G: 11.2410\n",
      "Epoch 42 | D: 0.1799 | G: 9.8327\n",
      "Epoch 43 | D: 0.1909 | G: 9.0671\n",
      "Epoch 44 | D: 0.1698 | G: 9.8328\n",
      "Epoch 45 | D: 0.3211 | G: 9.1793\n",
      "Epoch 46 | D: 0.3724 | G: 9.9088\n",
      "Epoch 47 | D: 0.6993 | G: 8.9724\n",
      "Epoch 48 | D: 0.4522 | G: 7.9705\n",
      "Epoch 49 | D: 0.5499 | G: 7.9216\n",
      "Epoch 50 | D: 0.5832 | G: 7.9464\n",
      "Epoch 51 | D: 0.6503 | G: 7.1976\n",
      "Epoch 52 | D: 0.6758 | G: 7.5383\n",
      "Epoch 53 | D: 0.5820 | G: 6.9765\n",
      "Epoch 54 | D: 0.5120 | G: 7.2130\n",
      "Epoch 55 | D: 0.6623 | G: 6.8444\n",
      "Epoch 56 | D: 0.5335 | G: 7.2967\n",
      "Epoch 57 | D: 0.6338 | G: 7.3503\n",
      "Epoch 58 | D: 0.6706 | G: 6.7277\n",
      "Epoch 59 | D: 0.5904 | G: 6.5228\n",
      "Epoch 60 | D: 0.5554 | G: 6.7160\n",
      "Epoch 61 | D: 0.6348 | G: 7.2009\n",
      "Epoch 62 | D: 0.5715 | G: 6.2736\n",
      "Epoch 63 | D: 0.6859 | G: 5.5097\n",
      "Epoch 64 | D: 0.6364 | G: 6.2095\n",
      "Epoch 65 | D: 0.6301 | G: 6.0855\n",
      "Epoch 66 | D: 0.6305 | G: 5.9444\n",
      "Epoch 67 | D: 0.5877 | G: 6.0684\n",
      "Epoch 68 | D: 0.5809 | G: 6.2486\n",
      "Epoch 69 | D: 0.6038 | G: 6.1012\n",
      "Epoch 70 | D: 0.6097 | G: 5.7928\n",
      "Epoch 71 | D: 0.6813 | G: 6.2953\n",
      "Epoch 72 | D: 0.5867 | G: 5.9890\n",
      "Epoch 73 | D: 0.6131 | G: 5.8618\n",
      "Epoch 74 | D: 0.5890 | G: 6.0367\n",
      "Epoch 75 | D: 0.6153 | G: 5.9524\n",
      "Epoch 76 | D: 0.6193 | G: 6.9587\n",
      "Epoch 77 | D: 0.5944 | G: 5.8626\n",
      "Epoch 78 | D: 0.6060 | G: 5.6880\n",
      "Epoch 79 | D: 0.6271 | G: 5.7031\n",
      "Epoch 80 | D: 0.5260 | G: 6.4244\n",
      "Epoch 81 | D: 0.5654 | G: 5.4321\n",
      "Epoch 82 | D: 0.5525 | G: 6.2042\n",
      "Epoch 83 | D: 0.7302 | G: 5.4278\n",
      "Epoch 84 | D: 0.5989 | G: 5.8593\n",
      "Epoch 85 | D: 0.5823 | G: 5.7840\n",
      "Epoch 86 | D: 0.5921 | G: 5.2372\n",
      "Epoch 87 | D: 0.5480 | G: 6.2234\n",
      "Epoch 88 | D: 0.5521 | G: 5.4826\n",
      "Epoch 89 | D: 0.6047 | G: 5.5353\n",
      "Epoch 90 | D: 0.5409 | G: 6.0159\n",
      "Epoch 91 | D: 0.6312 | G: 5.7206\n",
      "Epoch 92 | D: 0.5705 | G: 5.1285\n",
      "Epoch 93 | D: 0.5758 | G: 5.9831\n",
      "Epoch 94 | D: 0.5812 | G: 5.6215\n",
      "Epoch 95 | D: 0.5688 | G: 6.3437\n",
      "Epoch 96 | D: 0.5759 | G: 5.8564\n",
      "Epoch 97 | D: 0.5462 | G: 5.9623\n",
      "Epoch 98 | D: 0.5858 | G: 5.0835\n",
      "Epoch 99 | D: 0.5818 | G: 6.0336\n",
      "Epoch 100 | D: 0.5220 | G: 5.7968\n",
      "Epoch 101 | D: 0.6478 | G: 5.1542\n",
      "Epoch 102 | D: 0.6741 | G: 4.9143\n",
      "Epoch 103 | D: 0.6259 | G: 5.0348\n",
      "Epoch 104 | D: 0.6009 | G: 5.2521\n",
      "Epoch 105 | D: 0.5945 | G: 4.6147\n",
      "Epoch 106 | D: 0.6389 | G: 5.2130\n",
      "Epoch 107 | D: 0.5811 | G: 5.0234\n",
      "Epoch 108 | D: 0.5475 | G: 5.4490\n",
      "Epoch 109 | D: 0.5486 | G: 5.3211\n",
      "Epoch 110 | D: 0.7438 | G: 4.9977\n",
      "Epoch 111 | D: 0.6041 | G: 5.4195\n",
      "Epoch 112 | D: 0.5919 | G: 5.0466\n",
      "Epoch 113 | D: 0.5900 | G: 5.2962\n",
      "Epoch 114 | D: 0.6130 | G: 5.0005\n",
      "Epoch 115 | D: 0.5635 | G: 4.9186\n",
      "Epoch 116 | D: 0.6949 | G: 5.5828\n",
      "Epoch 117 | D: 0.6437 | G: 4.4384\n",
      "Epoch 118 | D: 0.5939 | G: 4.6819\n",
      "Epoch 119 | D: 0.6130 | G: 5.2890\n",
      "Epoch 120 | D: 0.6429 | G: 4.6483\n",
      "Epoch 121 | D: 0.6059 | G: 4.5689\n",
      "Epoch 122 | D: 0.5756 | G: 4.4857\n",
      "Epoch 123 | D: 0.5779 | G: 5.1395\n",
      "Epoch 124 | D: 0.5643 | G: 4.8815\n",
      "Epoch 125 | D: 0.6906 | G: 6.2343\n",
      "Epoch 126 | D: 0.6315 | G: 5.0772\n",
      "Epoch 127 | D: 0.7350 | G: 5.1618\n",
      "Epoch 128 | D: 0.5917 | G: 4.5795\n",
      "Epoch 129 | D: 0.5755 | G: 4.9472\n",
      "Epoch 130 | D: 0.5610 | G: 4.2898\n",
      "Epoch 131 | D: 0.4872 | G: 5.0630\n",
      "Epoch 132 | D: 0.5405 | G: 4.6322\n",
      "Epoch 133 | D: 0.5484 | G: 5.0013\n",
      "Epoch 134 | D: 0.5375 | G: 5.1299\n",
      "Epoch 135 | D: 0.6075 | G: 4.9275\n",
      "Epoch 136 | D: 0.5881 | G: 4.8587\n",
      "Epoch 137 | D: 0.5195 | G: 4.8691\n",
      "Epoch 138 | D: 0.5343 | G: 4.8183\n",
      "Epoch 139 | D: 0.6255 | G: 4.5038\n",
      "Epoch 140 | D: 0.5118 | G: 4.8380\n",
      "Epoch 141 | D: 0.5273 | G: 4.7399\n",
      "Epoch 142 | D: 0.5949 | G: 4.5046\n",
      "Epoch 143 | D: 0.6595 | G: 5.6425\n",
      "Epoch 144 | D: 0.6073 | G: 4.6449\n",
      "Epoch 145 | D: 0.5883 | G: 4.5868\n",
      "Epoch 146 | D: 0.6353 | G: 4.3546\n",
      "Epoch 147 | D: 0.5286 | G: 4.8636\n",
      "Epoch 148 | D: 0.5252 | G: 4.6725\n",
      "Epoch 149 | D: 0.4623 | G: 4.5462\n",
      "Epoch 150 | D: 0.5260 | G: 4.4512\n",
      "Epoch 151 | D: 0.5534 | G: 4.0708\n",
      "Epoch 152 | D: 0.5543 | G: 4.7327\n",
      "Epoch 153 | D: 0.5868 | G: 5.4074\n",
      "Epoch 154 | D: 0.5324 | G: 4.5253\n",
      "Epoch 155 | D: 0.4964 | G: 4.7551\n",
      "Epoch 156 | D: 0.5401 | G: 5.2623\n",
      "Epoch 157 | D: 0.4926 | G: 4.6378\n",
      "Epoch 158 | D: 0.5383 | G: 5.4394\n",
      "Epoch 159 | D: 0.5434 | G: 4.8141\n",
      "Epoch 160 | D: 0.5628 | G: 5.1951\n",
      "Epoch 161 | D: 0.6517 | G: 4.0402\n",
      "Epoch 162 | D: 0.5672 | G: 4.8112\n",
      "Epoch 163 | D: 0.5389 | G: 4.5988\n",
      "Epoch 164 | D: 0.5284 | G: 4.3097\n",
      "Epoch 165 | D: 0.4890 | G: 5.5067\n",
      "Epoch 166 | D: 0.5528 | G: 6.2958\n",
      "Epoch 167 | D: 0.6524 | G: 4.5371\n",
      "Epoch 168 | D: 0.5512 | G: 4.4034\n",
      "Epoch 169 | D: 0.5734 | G: 4.6161\n",
      "Epoch 170 | D: 0.5240 | G: 4.0602\n",
      "Epoch 171 | D: 0.5058 | G: 4.3675\n",
      "Epoch 172 | D: 0.6046 | G: 3.9818\n",
      "Epoch 173 | D: 0.4888 | G: 4.3184\n",
      "Epoch 174 | D: 0.4867 | G: 4.8806\n",
      "Epoch 175 | D: 0.4838 | G: 4.8395\n",
      "Epoch 176 | D: 0.5157 | G: 4.8134\n",
      "Epoch 177 | D: 0.4293 | G: 4.8031\n",
      "Epoch 178 | D: 0.5081 | G: 6.2375\n",
      "Epoch 179 | D: 0.5919 | G: 4.8888\n",
      "Epoch 180 | D: 0.5492 | G: 4.4524\n",
      "Epoch 181 | D: 0.6252 | G: 4.1588\n",
      "Epoch 182 | D: 0.5492 | G: 4.6950\n",
      "Epoch 183 | D: 0.5451 | G: 3.9283\n",
      "Epoch 184 | D: 0.4651 | G: 4.8083\n",
      "Epoch 185 | D: 0.5270 | G: 5.0775\n",
      "Epoch 186 | D: 0.5201 | G: 5.2028\n",
      "Epoch 187 | D: 0.6290 | G: 4.7990\n",
      "Epoch 188 | D: 0.5880 | G: 4.5566\n",
      "Epoch 189 | D: 0.5293 | G: 4.0535\n",
      "Epoch 190 | D: 0.5169 | G: 4.4343\n",
      "Epoch 191 | D: 0.5491 | G: 3.9314\n",
      "Epoch 192 | D: 0.5096 | G: 4.4551\n",
      "Epoch 193 | D: 0.5252 | G: 5.0196\n",
      "Epoch 194 | D: 0.6064 | G: 3.4582\n",
      "Epoch 195 | D: 0.5686 | G: 4.4483\n",
      "Epoch 196 | D: 0.5307 | G: 3.9027\n",
      "Epoch 197 | D: 0.5632 | G: 4.6901\n",
      "Epoch 198 | D: 0.5618 | G: 4.8137\n",
      "Epoch 199 | D: 0.5389 | G: 4.6370\n"
     ]
    }
   ],
   "source": [
    "dataset = FaceDataset(\"train\")\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "G = UNetGenerator().to(DEVICE)\n",
    "G.eval()\n",
    "D = PatchDiscriminator().to(DEVICE)\n",
    "\n",
    "opt_G = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "opt_D = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "criterion_GAN = nn.BCEWithLogitsLoss()\n",
    "criterion_L1 = nn.L1Loss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for real, comic in loader:\n",
    "        real, comic = real.to(DEVICE), comic.to(DEVICE)\n",
    "\n",
    "        # ---------------------\n",
    "        # Train Discriminator\n",
    "        # ---------------------\n",
    "        fake = G(real)\n",
    "\n",
    "        D_real = D(real, comic)\n",
    "        D_fake = D(real, fake.detach())\n",
    "\n",
    "        loss_D = (criterion_GAN(D_real, torch.ones_like(D_real)) +\n",
    "                  criterion_GAN(D_fake, torch.zeros_like(D_fake))) * 0.5\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        # -----------------\n",
    "        # Train Generator\n",
    "        # -----------------\n",
    "        D_fake = D(real, fake)\n",
    "        loss_G = criterion_GAN(D_fake, torch.ones_like(D_fake)) + \\\n",
    "                 LAMBDA_L1 * criterion_L1(fake, comic)\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "    print(f\"Epoch {epoch} | D: {loss_D.item():.4f} | G: {loss_G.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98ea9197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator saved!\n"
     ]
    }
   ],
   "source": [
    "# After training finishes\n",
    "torch.save(G.state_dict(), \"pix2pix_generator_128.pth\")\n",
    "print(\"Generator saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98f99b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        def down(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 4, 2, 1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        def up(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_c, out_c, 4, 2, 1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.d1 = down(3, 64)\n",
    "        self.d2 = down(64, 128)\n",
    "        self.d3 = down(128, 256)\n",
    "        self.d4 = down(256, 512)\n",
    "\n",
    "        self.u1 = up(512, 256)\n",
    "        self.u2 = up(512, 128)\n",
    "        self.u3 = up(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.d1(x)\n",
    "        d2 = self.d2(d1)\n",
    "        d3 = self.d3(d2)\n",
    "        d4 = self.d4(d3)\n",
    "\n",
    "        u1 = self.u1(d4)\n",
    "        u2 = self.u2(torch.cat([u1, d3], 1))\n",
    "        u3 = self.u3(torch.cat([u2, d2], 1))\n",
    "\n",
    "        return self.final(torch.cat([u3, d1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "682b555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetGenerator(\n",
       "  (d1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (d2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (d3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (d4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (u1): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (u2): Sequential(\n",
       "    (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (u3): Sequential(\n",
       "    (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = UNetGenerator().to(DEVICE)\n",
    "G.load_state_dict(torch.load(\"pix2pix_generator_128.pth\", map_location=DEVICE))\n",
    "G.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fdf70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "037f6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_comic(input_path, output_path):\n",
    "    img = Image.open(input_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    fake = G(x)\n",
    "\n",
    "    # De-normalize\n",
    "    fake = (fake.squeeze(0) + 1) / 2\n",
    "    fake = fake.clamp(0, 1)\n",
    "\n",
    "    out = transforms.ToPILImage()(fake.cpu())\n",
    "    out.save(output_path)\n",
    "\n",
    "    print(\"Saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0676d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: face.png\n"
     ]
    }
   ],
   "source": [
    "generate_comic(\n",
    "    input_path=\"face.6.jpg\",\n",
    "    output_path=\"face.png\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
